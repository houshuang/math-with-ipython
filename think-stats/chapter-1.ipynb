{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Chapter 1: Statistical thinking for programmers\n",
      "\n",
      "- probability: study of random events\n",
      "- statistics: using data samples to support claims about populations\n",
      "- computation: tool for quantitative analysis\n",
      "\n",
      "## Do first babies arrive late?\n",
      "\n",
      "### Anecdotal evidence problems:\n",
      "- small n of observations\n",
      "- selection bias: people joining discussion because babies born late\n",
      "- confirmation bias: more likely to cite evidence if you support something\n",
      "- inaccuracy\n",
      "\n",
      "### Steps:\n",
      "- data collection\n",
      "- descriptive stats\n",
      "- exploratory data analysis: look for patterns, differences, features. Check for inconsistencies, identify limitations.\n",
      "- hypothesis testing: is effect real?\n",
      "- estimation: use data from ample to estimate characteristics of the general population.\n",
      "\n",
      "### NSFG\n",
      "Cross-sectional study. Target population: US citizens, 15-44. Respondents/cohort. Meant to be representative. Deliberatively oversampled. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Had to convert a few print statements to get it to work on Python 3\n",
      "# http://www.thinkstats.com/survey.py\n",
      "%run \"vendor/survey.py\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of respondents 7643\n",
        "Number of pregnancies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13593\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Let me see if I can do this with Pandas as well?\n",
      "I first Googled parsing binary files, but it turns out it's not really a binary file, but a fixed-width file. I did peak at the survey code a bit. To me, it's more intuitive to write functions that creats dicts, than classes. Then import it into Pandas. Probably not the most efficient, but seems to work. \n",
      "\n",
      "Still a bit confused about how to split my vars, functions, imports etc in IPython. In a script, imports should be at the top, but in IPython you want to be able to see the progress of thinking, without rewriting the whole thing to reflect the final vision."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fields= [\n",
      "    ('caseid', 1, 12, int),\n",
      "    ('nbrnaliv', 22, 22, int),\n",
      "    ('babysex', 56, 56, int),\n",
      "    ('birthwgt_lb', 57, 58, int),\n",
      "    ('birthwgt_oz', 59, 60, int),\n",
      "    ('prglength', 275, 276, int),\n",
      "    ('outcome', 277, 277, int),\n",
      "    ('birthord', 278, 279, int),\n",
      "    ('agepreg', 284, 287, int),\n",
      "    ('finalwgt', 423, 440, float),\n",
      "]\n",
      "\n",
      "def parse(fields, line):\n",
      "    res = []\n",
      "    for (field, start, end, cast) in fields:\n",
      "        try:\n",
      "            chunk = line[start-1:end]\n",
      "            chunkproc = cast(chunk)\n",
      "            res.append( (field, chunkproc) )\n",
      "        except ValueError:\n",
      "            pass\n",
      "    return dict(res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 223
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import DataFrame\n",
      "import pandas as pd\n",
      "import gzip\n",
      "\n",
      "pregfile = \"/Users/Stian/src/math-with-ipython/think-stats/vendor/2002FemPreg.dat.gz\"\n",
      "\n",
      "preg = []\n",
      "for line in gzip.open(pregfile):\n",
      "    preg.append(parse(fields, line))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 225
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instinctively, I don't like assigning the empty [] container, just to fill it up in the list comprehension... I know this is less Pythonic, but I kind of enjoy it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from toolz import partial\n",
      "\n",
      "preg2 = list(map(partial(parse,fields), gzip.open(pregfile)))\n",
      "\n",
      "preg2 == preg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 226,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 226
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Silly me, I just realized I should use a list comprehension -- nice and clean and Pythonic, without any stray container variables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "preg3 = [parse(fields, line) for line in gzip.open(pregfile)]\n",
      "preg3 == preg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 227,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = DataFrame(preg)\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>agepreg</th>\n",
        "      <th>babysex</th>\n",
        "      <th>birthord</th>\n",
        "      <th>birthwgt_lb</th>\n",
        "      <th>birthwgt_oz</th>\n",
        "      <th>caseid</th>\n",
        "      <th>finalwgt</th>\n",
        "      <th>nbrnaliv</th>\n",
        "      <th>outcome</th>\n",
        "      <th>prglength</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 3316</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 8</td>\n",
        "      <td> 13</td>\n",
        "      <td> 1</td>\n",
        "      <td>  6448.271112</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 39</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 3925</td>\n",
        "      <td> 2</td>\n",
        "      <td> 2</td>\n",
        "      <td> 7</td>\n",
        "      <td> 14</td>\n",
        "      <td> 1</td>\n",
        "      <td>  6448.271112</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 39</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1433</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 9</td>\n",
        "      <td>  2</td>\n",
        "      <td> 2</td>\n",
        "      <td> 12999.542264</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 39</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1783</td>\n",
        "      <td> 2</td>\n",
        "      <td> 2</td>\n",
        "      <td> 7</td>\n",
        "      <td>  0</td>\n",
        "      <td> 2</td>\n",
        "      <td> 12999.542264</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 39</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 1833</td>\n",
        "      <td> 2</td>\n",
        "      <td> 3</td>\n",
        "      <td> 6</td>\n",
        "      <td>  3</td>\n",
        "      <td> 2</td>\n",
        "      <td> 12999.542264</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 39</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 10 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 178,
       "text": [
        "   agepreg  babysex  birthord  birthwgt_lb  birthwgt_oz  caseid      finalwgt  \\\n",
        "0     3316        1         1            8           13       1   6448.271112   \n",
        "1     3925        2         2            7           14       1   6448.271112   \n",
        "2     1433        1         1            9            2       2  12999.542264   \n",
        "3     1783        2         2            7            0       2  12999.542264   \n",
        "4     1833        2         3            6            3       2  12999.542264   \n",
        "\n",
        "   nbrnaliv  outcome  prglength  \n",
        "0         1        1         39  \n",
        "1         1        1         39  \n",
        "2         3        1         39  \n",
        "3         1        1         39  \n",
        "4         1        1         39  \n",
        "\n",
        "[5 rows x 10 columns]"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There's also a bit of recoding happening, dividing the mother's age by 100, and converting weight to ounces. (I'll convert it to SI too, since I'm more comfortable with that). This is all very easy with Pandas - and I think clearer to do this after importing, rather than with some magic in the import function.\n",
      "\n",
      "I struggled a bit with the advanced query and assignment. Goal was to simplify this:\n",
      "\n",
      "    if (rec.birthwgt_lb != 'NA' and rec.birthwgt_lb < 20 and\n",
      "        rec.birthwgt_oz != 'NA' and rec.birthwgt_oz <= 16):\n",
      "        rec.totalwgt_oz = rec.birthwgt_lb * 16 + rec.birthwgt_oz\n",
      "    else:\n",
      "        rec.totalwgt_oz = 'NA'```\n",
      "\n",
      "This:\n",
      "\n",
      "    df.query('birthwgt_lb < 20 & birthwgt_oz <= 16')```\n",
      "\n",
      "loooks great and parsimonius, but returns a copied slice, and does not allow assignment. The final version works well too, once I figured out that I had to include the column to be assigned to in the [], rather than using ```df[bool][col] = ...```\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.agepreg = df.agepreg/100\n",
      "df.loc[(df.birthwgt_lb < 20) & (df.birthwgt_oz <= 16), 'totalwgt_oz'] = \\\n",
      "    df.birthwgt_lb*16 + df.birthwgt_oz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 1.3.2\n",
      "Supposed to write a loop to count number of live births, let's use Pandas instead. Initially I counted babysex, but that only gave me the live births, since the other categories have NaN. (value_counts() is nice, like table() in R. Groupby also works, an earlier SO entry seems to indicate that it's a lot slower, but currently it seems to be slightly faster)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.outcome.value_counts()\n",
      "# also possible:\n",
      "# df.groupby('outcome').size()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1000 loops, best of 3: 720 \u00b5s per loop\n",
        "1000 loops, best of 3: 973 \u00b5s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 1.3.3\n",
      "Partition live births into two groups, one for first babies, and one for others. (Might be able to do this more elegantly, by using np.where and groupby or something, but not worth it for just these two groups I think -- would be nice if query worked like a groupby, giving both the result and its negation).\n",
      "\n",
      "This also works, but is much less clear:\n",
      "\n",
      "    birthgroups = df[df.outcome==1].groupby(df.birthord==1).groups\n",
      "    firstbirth = df.loc[birthgroups[0]]\n",
      "    secondplusbirth = df.loc[birthgroups[1]]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df1 = df.query('outcome==1 & birthord==1')\n",
      "dfnot1 = df.query('outcome==1 & birthord != 1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(np.average(df1.prglength), np.average(dfnot1.prglength))\n",
      "\n",
      "# Let's do it manually as well\n",
      "def mean_(x):\n",
      "    return(sum(x)/len(x))\n",
      "print(mean_(df1.prglength), mean(dfnot1.prglength))\n",
      "\n",
      "%timeit np.average(df1.prglength)\n",
      "%timeit np.mean(df1.prglength)\n",
      "%timeit mean_(df1.prglength)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "38.6009517335 38.5229144667\n",
        "38.6009517335 38.5229144667\n",
        "10000 loops, best of 3: 62.9 \u00b5s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10000 loops, best of 3: 117 \u00b5s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10000 loops, best of 3: 135 \u00b5s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 172
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "According to the book, first babies are born 13 hours later. Let's check."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(mean_(df1.prglength) - mean_(dfnot1.prglength)) * 7 * 24"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 176,
       "text": [
        "13.110260818628319"
       ]
      }
     ],
     "prompt_number": 176
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Conclusion\n",
      "That was the end of chapter one. Pretty basic stuff so far, but I'm glad I worked my way through it -- it gave me a chance to become more familiar with the IPython interface, and it was fun looking at the author's code and reimplementing it in Python. The indexing and assigning gave me the most trouble - some of these restrictions seem to stem from the underlying Numpy NDArray deciding to create a copy instead of a view. Fascinating to see the example code the author provided -- very different from any I would write, and I really enjoy using Pandas, but valuable to see different approaches. (And Pandas wasn't around when he began writing his book). \n",
      "\n",
      "I will store the Pandas arrays, and continue working with them in the next chapter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "with open(\"/Users/Stian/src/math-with-ipython/think-stats/preg-pandas.pickle\", \"wb\") as f:\n",
      "    pickle.dump([df,df1,dfnot1], f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 295
    }
   ],
   "metadata": {}
  }
 ]
}